有效且鲁棒的近似最近点

使用分层导航的邻居搜索小世界图


提出了一种基于层次可控的可导航小世界图的近似 k
最近邻搜索方法。提出的解决方案完全基于图，不需要任何额外的搜索结构，这通常是在粗搜索阶段使用的最接近图技术。Hierarchical
NSW
逐步构建了一个多层结构，由层次化的邻近图(层)组成，用于存储元素的嵌套子集。元素存在的最大层是随机选择的，具有指数衰减概率分布。这允许生成类似于先前研究的
Navigable Small World
(NSW)结构的图形，同时还允许通过特征距离尺度分隔链接。与新南威尔士州相比，从上层开始搜索和利用尺度分离提高了性能，并允许对数复杂度缩放。附加使用启发式选择邻近图邻居显着提高性能在高召回和高聚集数据的情况下。绩效评价表明，拟议的通用度量空间搜索指数能够大大优于以往的开源最新矢量方法。算法与跳过列表结构的相似性允许直接平衡的分布式实现。

索引术语ー图与树搜索策略、人工智能、信息搜索与检索、信息存储与检索、信息技术与系统、搜索过程、图与网络、数据结构、最近邻搜索、大数据、近似搜索、相似搜索ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー

1引言

随着可用信息资源的不断增加，对最近邻搜索数据结构的可扩展性和有效性提出了更高的要求。一种常用的信息搜索方法是
k 最近邻搜索(K-NNS)。K-
神经网络假设您在数据元素之间有一个定义的距离函数，目的是从数据集中找到 k
元素，从而最小化到给定查询的距离。这些算法被广泛应用于非参数机器学习算法、大规模数据库中的图像特征匹配和语义文献检索等领域。一种简单的
K-NNS
方法是计算查询与数据集中每个元素之间的距离，并以最小距离选择元素。不幸的是，这种天真的方法的复杂性与存储元素的数量呈线性关系，这使得它不适用于大规模的数据集。这导致了人们对开发快速和可扩展的
K-NNS 算法的高度兴趣。

对于 K-NNS
\[3-5\]的精确解可以提供一个实质性的搜索加速，只有在相对低维数据由于"维数灾难"的情况下。为了解决这一问题，提出了近似最近邻搜索(K-ANNS)的概念，它通过允许少量的ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー。邮箱:
yurymalkov@mail.ru。

亚舒宁。地址: 31-33 ul。Krasnozvezdnaya，603104 Nizhny Novgorod，Russia
俄罗斯。电子邮件: yashuninda@yandex.ru
errors。不精确搜索(召回)的质量被定义为找到的真正最近邻居的数量与 k
之间的比率。最流行的 k-ann 解决方案是基于近似的树算法\[6,7\]
，局部性敏感哈希(LSH)\[8,9\]和产品量化(PQ)\[10-17\]。接近图 K-ANNS
算法\[10,18-26\]最近获得了流行性，在高维数据集上提供了更好的性能。然而，在低维或聚集数据的情况下，邻近图路由的幂律缩放导致极端的性能降低。

本文提出了一种新的基于完全图的增量式 K-ANNS
结构------分层导航小世界(Hierarchical NSW，HNSW)
，它可以提供更好的对数复杂度缩放。其主要贡献是:
显式选择图的入口点节点，不同尺度的链路分离和使用先进的启发式选择邻居。或者，分层
NSW
算法可以被视为具有接近图而不是链表的概率跳过列表结构\[27\]的扩展。Perfor-mance
评价表明，所提出的一般度量空间方法能够强有力地超越以往的开源最先进的方法只适用于向量空间。

这项工作已经提交给 IEEE
可能的出版物。版权可能在没有通知的情况下转让，之后这个版本可能不再可访问。

2相关工程

2.1接近图技术

在绝大多数研究的图形算法中，搜索采用了一种形式的贪婪路由在 k
最近邻(k-NN)图\[10,18-26\]。对于给定的接近图，我们从某个入口点开始搜索(它可以是随机的，也可以由单独的算法提供)
，然后迭代遍历该图。在遍历的每一步，算法检查从查询到当前基本节点的邻居的距离，然后选择邻居节点作为下一个基本节点，最小化距离，同时始终跟踪最佳发现的邻居。当满足一些停止条件(例如距离计算的次数)时，搜索就会终止。与
k-NN 图中最近邻的链接可以作为 Delaunay
图\[25,26\]的简单近似(这个图可以保证基本贪婪图遍历的结果始终是最近邻)。不幸的是，Delaunay
图不能有效地构造没有关于空间结构的先验信息\[4\]
，但它的近似由最近的邻居可以做只使用存储元素之间的距离。结果表明，这种近似的邻近图方法具有与其他
k-ann 方法相竞争的性能，如 kd 树和 LSH \[18-26\]。

k-NN 图方法的主要缺点是:
1)在路由过程中，步骤数与数据集大小的幂律比例\[28,29\] ;
2)可能丧失全局连通性，导致对聚类数据的搜索结果不佳。为了克服这些问题，人们提出了许多混合算法，使用只适用于矢量数据的辅助算法(如
chaskd 树\[18,19\]和乘积量化\[10\]) ，通过粗搜索找到更好的候选输入节点。

在\[25,26,30\]中，作者提出了一种称为 Navigable Small World (NSW，也称为
Metricized Small World，MSW)的接近图 K-ANNS
算法，该算法利用可导航图，即在贪婪遍历过程中跳数对数或多对数缩放的图，其网络大小\[31,32\]。新南威尔士州图是通过连续插入元素的随机序列，双向联合连接他们的
m
最接近的邻居，从先前插入的元素。使用结构的搜索过程(多个随机输入节点的贪婪搜索的一种变体)找到
m
个最近的邻居。链接到最近的邻居的元素插入在建设开始后，成为桥梁之间的网络枢纽，保持整体图连通性，并允许对数缩放的数量跳贪婪路由。

NSW
结构的构造阶段不需要全局同步，也不会对精度产生可测量的影响，可以有效地进行并行化，是分布式搜索系统的一个很好的选择。新南威尔士州方法在一些数据集上提供了最先进的性能\[33,34\]
，但是，由于整体多对数级复杂度缩放，该算法在低维数据集上仍然容易出现严重的性能下降(在这种情况下，新南威尔士州可能会输给基于树的算法几个数量级\[34\])。

2.2可导航的小世界模型

贪婪图路由的对数或多对数缩放的网络被称为可导航的小世界网络\[31,32\]。这种网络是复杂网络理论的一个重要课题，旨在理解现实网络形成的基本机制，以便将其应用于可扩展路由\[32,35,36\]和分布式最近邻搜索\[25,26,30,37-40\]。

第一个考虑可航行网络的空间模型的工作是由 J.Kleinberg
\[31,41\]作为著名的米尔格拉姆实验的社会网络模型\[42\]完成的。Kleinberg
研究了随机 Watts-Strogatz 网络的一个变体\[43\] ，使用了 d
维向量空间中的一个正则格图，并根据一个特定的长链长度分布
r-"增加了长程链路。对于 a =
d，通过贪婪路由到达目标的跳数按多对数标度(而不是任何其他值为 α
的幂定律)。这个想法启发了基于导航效应的许多 K-NNS 和 K-ANNS
算法的开发\[37-40\]。但是，即使 Kleinberg
的导航准则原则上可以扩展到更一般的空间，为了建立这样一个导航网络，人们必须事先知道数据的分布情况。此外，Kleinberg
图中的贪婪路由充其量只能算是多对数麦克复杂度的可伸缩性。

另一类众所周知的可导航网络是无标度模型\[32,35,36\]
，它可以再现现实生活中的网络的一些特征，并广告为路由应用程序\[35\]。然而，由这些模型产生的网络具有更糟糕的幂律复杂度的贪婪搜索\[44\]
，并且，正如 Klein-berg
的模型，无标度模型需要全球知识的数据分布，使他们不能用于搜索应用程序。

上述 NSW
算法使用了一个简单的，以前未知的导航网络模型，允许分散图的构造，并适用于任意空间的数据。\[44\]新南威尔士州网络的形成机制可能是大规模生物神经网络通航性的原因(其存在是有争议的)
:
相似模型能够描述小脑网络的生长，而该模型预测了在大规模神经网络中观察到的几个高层次特征。然而，新南威尔士州模型也受到路由过程的多对数搜索复杂性的影响。

3动机

通过对路由过程的分析，可以找到提高新南威尔士搜索复杂度的方法，这一点在\[32,44\]中进行了详细的研究。路由可以分为两个阶段:
"缩小"和"缩小"\[32\]。贪婪算法从低度节点的"缩小"阶段开始，同时遍历图，增加节点的度数，直到节点链路长度的特征半径达到查询距离的尺度。在后一种情况发生之前，节点的平均度可以保持相对较小，这就增加了陷入远距离假局部极小值的概率。

通过从具有最大度的节点(好的候选节点是插入到 NSW
结构中的第一个节点\[44\])开始搜索，直接进入搜索的"放大"阶段，可以避免在
NSW
中描述的问题。测试表明，将集线器设置为起始点大大增加了结构中成功路由的可能性，并在低维数据上提供了显着更好的性能。然而，它仍然只有一个贪婪搜索的多对数复杂度可伸缩性，并且在高维数据上的性能比层次
NSW 要差。

新南威尔士州单个贪婪搜索的多对数复杂度是由于距离计算的总数与贪婪算法平均跳数乘以贪婪路径上节点的平均度大致成正比。平均跳数以对数方式递增\[26,44\]
，而贪婪路径上节点的平均度也以对数方式递增，这是因为:
1)贪婪搜索倾向于经过与网络增长相同的集线器\[32,44\] ;
2)集线器连接的平均数随着网络规模的增加以对数方式递增。因此，我们得到了由此产生的复杂性的总体极对数依赖性。

层次 NSW
算法的思想是根据链路的长度尺度将链路分割成不同的层，然后在多层图中进行搜索。在这种情况下，我们只能评估每个元素所需的固定连接部分，而不依赖于网络大小，因此允许对数可伸缩性。在这种结构中，搜索从上层开始

![](media/image1.jpeg){width="2.4722222222222223in"
height="2.611111111111111in"}

图1。新南威尔士州分层理念的说明。搜索从顶层的一个元素开始(显示为红色)。红色箭头显示贪婪算法从入口点到查询的方向(绿色显示)。

最长的链接("放大"阶段)。该算法贪婪地从上层遍历元素，直到达到局部最小值(参见图1)。之后，搜索切换到较低层(链接较短)
，从前一层的局部最小元素重新开始，然后重复进程。所有层中每个元素的最大连接数可以保持不变，从而允许在一个可导航的小型世界网络中对数复杂度的路由扩展。

形成这种分层结构的一种方法是通过引入层来明确地设置具有不同长度尺度的链路。对于每个元素，我们选择一个整数级别
l
来定义元素所属的最大层。对于一个层中的所有元素，一个接近图(即只包含近似
Delaunay 图的"短"链接的图)是增量构建的。如果我们设置一个展开衰减概率为 l
(即遵循一个几何分布)
，我们得到了结构中预期层数的对数标度。搜索过程是一个从顶层开始到零层结束的迭代贪婪搜索。

如果我们合并来自所有层的连接，结构变得类似于 NSW 图(在这种情况下，l
可以放在对应于 NSW
中的节点度)。与新南威尔士州不同的是，新南威尔士州分层构造算法不需要在插入之前对元素进行置换------通过层次随机化实现了随机性，因此即使在临时改变数据分布的情况下也允许真正的增量索引(虽然改变插入的顺序仅仅因为部分去演化构造过程而略微改变了性能)。

新南威尔士的分层思想也与众所周知的1d 概率跳过列表结构非常相似\[27\]
，并且可以使用其术语进行描述。跳过列表的主要区别在于，我们通过用邻近图替换链表来概括该结构。层次结构

![](media/image2.jpeg){width="2.4583333333333335in"
height="2.5972222222222223in"}

![](media/image3.jpeg){width="1.4583333333333333in"
height="0.6388888888888888in"}

图2。用于为两个孤立的集群选择图形邻居的启发式算法的说明。在 Cluster
1的边界上插入一个新元素。元素的所有最近的邻居都属于簇1，因此在簇之间缺少
Delaunay 图的边。然而，启发式方法从 Cluster 2中选择元素
e2，从而在插入的元素与 Cluster 1中的任何其他元素相比最接近
e2的情况下保持全局连接性。

因此，NSW 方法可以使用相同的方法来制作分布式近似搜索/覆盖结构\[45\]。

对于元素插入过程中邻近图连接的选择，我们采用了一种考虑候选元素之间距离的启发式算法来创建不同的连接(在空间近似树\[4\]中使用了类似的算法来选择树的子节点)
，而不仅仅是选择最接近的邻居。启发式检查候选人从最近的(关于插入的元素)开始，并且只有当候选人比任何已经连接的候选人更接近基础(插入的)元素时，才创建与候选人的连接(详见第4节)。

当候选人数量足够大时，启发式算法允许得到精确的相对邻域图\[46\]作为子图，即
De-launay
图的最小子图，只需使用节点之间的距离即可推导出来。相对邻域图允许容易地保持全局连接元件(图论)
，即使在高度聚集的数据的情况下(见图2的说明)。请注意，与精确的相对邻域图相比，启发式算法创建了额外的边，允许控制连接的数量，这对搜索性能很重要。对于一维数据，启发式算法只使用元素之间的距离信息，就可以得到精确的
Delaunay 子图(在这种情况下，它与相对邻域图一致) ，从而直接从
Hierar-chical NSW 过渡到一维概率跳过列表算法。

文献中还使用了新南威尔士分层邻接图的 Base
变体。\[18\](称为"稀疏邻里关系图")用于邻近图搜索。类似的启发式算法也是
FANNG 算法的重点\[47\]

算法1

INSERT (hnsw，q，m，Mmax，efConstruction，mL)

Input: 多层图 hnsw，新元素 q，建立的连接数 m，每层每个元素的最大连接数
Mmax，动态候选列表 efConstruction 的大小，nor-

水平生成的极化系数

输出: 更新 hnsw 插入元素 q

1 w ←//list 用于当前找到的最近元素

2 ep ← get enter point for hnsw

3l ←对于 hns4l ←-ln (unif (0。1))∙ mL something//new element's level

5代表 lc ← l。 l + 1

6 w ← SEARCH-LAYER (q，ep，ef = 1，lc)

7 ep ←从 w 到 q 得到最接近的元素

Lc 为8← min (l，l) \... 0

9 w ← SEARCH-LAYER (q，ep，efConstruction，lc)

10个邻居← SELECT-NEIGHBORS (q，w，m，lc)//alg。3或
alg。如果需要的话，为每个 e ∈ neighbors//shrink connections
添加从邻居到第12层 q 的所有双向连接

13eConn ← neighborhood (e) at layer lc

如果 eConn \> Mmax//收缩 e 的连接

//如果 lc = 0，则 Mmax = Mmax0

15eNewConn ← SELECT-NEIGHBORS (e，eConn，Mmax，lc)

Alg. 3或 alg. 4

16set neighborhood (e) at layer lc to eNewConn

第17集← w

18如果 l \> l

19设置输入点为 hnsw 到 q

(在当前手稿的第一个版本被发布到网上后不久发表)
，基于稀疏邻域图的精确路由属性，略有不同的解释。

4算法描述

网络构造算法(alg。1)通过将存储的元素连续插入到图形结构中来组织。对于每个插入的元素，以指数衰减概率分布随机选择一个整数最大层
l (通过 mL 参数归一化，参见 alg 中的第4行)。1).

插入过程的第一阶段从顶层开始，贪婪地遍历图形，以便在图层中找到与插入元素
q 最接近的
ef。之后，算法继续从下一层搜索，使用从上一层找到的最接近的邻居作为输入点，然后重复该过程。每一层最近的邻居都是通过
alg
中描述的贪婪搜索算法的一个变体来找到的。2，这是\[26\]中算法的更新版本。为了获得某一层中的近似
ef 最近邻，在搜索过程中保留了一个 ef 最近发现元的动态列表 w
(最初用输入点填充)。通过计算列表中先前未计算的最近元素的邻域，在每个步骤中更新列表，直到计算列表中每个元素的邻域为止。与限制距离计算的数量相比，分层
NSW
停止条件有一个优势------它允许丢弃比列表中最远的元素离查询更远的候选者进行评估，从而避免搜索结构的膨胀。和新南威尔士州一样，为了获得更好的性能，列表通过两个优先级队列进行模拟。与
NSW (以及一些队列优化)的区别在于: 1)入口点是一个固定的参数;
2)搜索质量由一个不同的参数 ef (在 NSW \[26\]中设置为
k)控制，而不是改变多个搜索的数量。

算法2

搜索-层(q，ep，ef，lc)

输入: 查询元素 q，输入点 ep，最接近 qele 的数字

元素返回 ef，层数 lc

输出: 与 q 最接近的邻居

1 v ← ep//set of visited elements 1 v ← ep//访问过的元素集

2 c ← ep//set of candidates

3 w ← ep//发现最近邻居的动态列表

4而 c \> 0

5 c ←从 c 到 q 提取最近的元素6 f ←从 w 到 q 提取最远的元素

如果距离(c，q) \> 距离(f，q)

8break///w 中的所有元素被评估

层 lc//更新 c 和 w 上的每个 e ∈邻域(c)为9

10if e something v

11v ← v é e

←如果距离(e，q) \< 距离(f，q)或 w \< ef，则得到从 w 到 q13的最远元素

14C ← c something e

15W ← w something e

16if w \> ef

从 w 到 q 移除最远的元素

18回 w

算法3

SELECT-NEIGHBORS-SIMPLE (q，c，m)

输入: 基本元素 q，候选元素 c，返回 m 的邻居数

输出: m 个最接近 q 的元素

返回 m 个从 c 到 q 的最近元素

算法5

K-NN-SEARCH (hnsw，q，k，ef)

输入: 多层图 hnsw，查询元素 q，返回 k 的最近邻居数，动态候选列表 ef
的大小

输出: k 最接近于 q 的元素

1 w ← something//set 用于当前最近的元素

2 ep ← get enter point for hnsw

3l ←水平的 ep//上层为 hnsw

4代表 lc ← l. 1

5 w ← SEARCH-LAYER (q，ep，ef = 1，lc)

6 ep ←从 w 到 q 得到最近的元素

7w ← SEARCH-LAYER (q，ep，ef，lc = 0)

8返回从 w 到 q 的 k 个最接近的元素

在搜索的第一阶段，ef 参数被设置为1(简单的贪婪搜索)
，以避免引入额外的参数。

当搜索到等于或小于 l
的层时，构造算法的第二阶段就开始了。第二阶段的不同之处在于:
1)为了控制贪婪搜索过程的召回，将 ef 参数从1增加到 efConstruction;
2)将每一层上发现的最近邻居作为插入元素连接的候选对象。

考虑了从候选元素中选择 m 邻居的两种方法:
简单连接到最接近元素(alg。3)和解释候选元素之间的距离以创建不同方向的连接的启发式(alg。4)
，在第3节中描述。启发式有两个额外的参数: extendcandidate (默认设置为
false) ，它扩展了候选集，只对极端集群化的数据有用; keepPrunedConnections
允许每个元素获得固定数量的连接。元素每层可以有的最大连接数是由参数 Mmax
定义的，对于大于零的每一层(一个特殊的参数
mmax0分别用于地层)。如果一个节点在建立新连接时已经满了，那么它的扩展连接列表将通过用于邻居选择的相同算法(algs。3或4)。

当插入元素的连接建立在零层上时，插入过程终止。

提出了一种用于层次 NSW 的 k-ann 搜索算法。5.它大致相当于一个层为 l =
0的项目的插入算法。不同之处在于，在第一层找到的最接近的邻居被用作连接的候选者，现在作为搜索结果返回。搜索的质量由
ef 参数控制(对应于构造算法中的 efConstruction)。

算法4

SELECT-NEIGHBORS-HEURISTIC
(q，c，m，lc，extendcandidate，keep-PrunedConnections)

输入: 基本元素 q，候选元素 c，返回 m 的邻居数，层数
lc，标志是否扩展候选列表扩展候选元素，标志是否添加

17R ← r something 提取 Wd 到 q18的最近元素返回 r

4.1施工参数的影响

算法构造参数 mL 和 mmax0负责维持所构造图的小世界导航性。设置 mL
为零(这对应于图中的单层)和 mmax0为 m 导致生成有向 k-
神经网络图，其幂律搜索复杂性在\[21,29\]之前已经研究过了。3为邻居选择)。将
mL 设置为零，mmax0设置为无穷大导致生成具有多对数复杂性的 NSW
图\[25,26\]。最后，将 mL
设置为某个非零值会导致可控层次图的出现，通过引入层次，允许对数搜索的复杂性(参见第3节)。

为了获得可控层次结构的最佳性能优势，不同层次上的邻居之间的重叠(即同样属于其他层次的元素邻居的百分比)必须很小。为了减少重叠，我们需要减少毫升。然而，同时，在贪婪搜索过程中，每层的平均跳数都会增加，从而对性能产生负面影响。这导致
mL 参数的最佳值的存在。

最佳 mL 的一个简单选择是1/ln (m) ，这对应于跳过列表参数 p =
1/m，层之间的平均单个元素重叠。在 Intel Core i75930k CPU
上进行的仿真表明，建议的 mL 选择是一个合理的选择(参见图3关于10m 随机 d =
4个向量的数据)。此外，当 mL
从零增加时，该图显示了对低维数据的大规模加速，以及使用启发式选择图连接的效果。对于高维数据，很难期待相同的行为，因为在这种情况下，k-NN
图已经具有了

![](media/image4.jpeg){width="2.263888888888889in"
height="1.9027777777777777in"}

图3。对于 d = 4的10m 随机向量，查询时间与 mL 参数的曲线。用箭头显示 mL
的 au-toselected 值1/ln (m)。

![](media/image5.jpeg){width="2.1527777777777777in"
height="1.9722222222222223in"}

图4。对于 d = 1024的100k 随机向量，查询时间与 mL 参数的曲线。用箭头显示
mL 的自动选择值1/ln (m)。

![](media/image6.jpeg){width="2.2222222222222223in"
height="1.9166666666666667in"}

图5。5M SIFT 学习数据集的查询时间和 mL 参数的 plot。用箭头显示 mL
的自动选择值1/ln (m)。

非常短的贪婪算法路径\[28\]。令人惊讶的是，将 mL
从零增加会导致非常高维数据(100k 稠密的 ran-dom d =
1024个向量，见图4)的速度可测量地增加，而且不会对层次 NSW
方法带来任何惩罚。对于 SIFT
向量\[1\](它具有复杂的混合结构)这样的实际数据，通过增加 mL
的性能改进较高，但在当前设置中，与启发式改进相比，性能改进不那么显著(参见图5，对来自
BIG-ANN \[13\]学习集的500万个128维 SIFT 向量的1-nn 搜索性能)。

Mmax0的选择(一个元素在零层中可以有的最大连接数)也对搜索性能有很大的影响，特别是在高质量(高召回)搜索的情况下。仿真结果表明，将
mmax0设置为 m (如果不使用邻居选择启发式算法，则对应于各层上的 k-NN
图)将导致在高召回时非常强的性能损失。模拟还表明，2∙ m 是
mmax0的一个好选择:
设置更高的参数导致性能下降和过度的内存使用。在图6中，显示了依赖于 Mmax0
pa 参数(在 Intel Core i52400 CPU 上完成)的5m SIFT
学习数据集的搜索性能结果。建议的值在不同的召回情况下使性能接近最佳。

在所有考虑的情况下，使用启发式的邻近图邻居选择(alg。4)导致更高或类似的搜索性能相比，与最近邻居的天真连接(alg。3).这种影响在低维数据、高召回率的中维数据和高聚类数据的情况下最为突出(意识形态上的不连续性可以被视为局部低维特征)
，见图7中的比较(Core i52400 CPU)。当使用最近邻作为邻接图的连接时，层次
NSW
算法不能实现对聚类数据的高召回，因为搜索停留在聚类边界上。相反，当使用启发式(连同候选人的扩展，Alg
中的第3行)。4)聚类导致更高的性能。对于均匀和非常高维数据，邻居选择方法之间有一点差异(见图4)
，可能是因为在这种情况下，几乎所有的最近邻居都是通过启发式选择的。

留给用户的唯一有意义的构造参数是 m。M
的合理范围是5到48。模拟表明，较小的 m
通常对于较低的召回和/或较低的维数据产生较好的结果，而较大的 m
对于较高的召回和/或高维数据产生较好的结果(见图8说明，Core
i52400cpu)。该参数还定义了算法的内存消耗(与 m 成正比)
，因此应该谨慎选择。

efConstruction
参数的选择是直接的。正如在\[26\]中所建议的那样，它必须足够大，以便在构建过程中产生接近统一的
K-ANNS
召回(对于大多数用例来说，0.95就足够了)。正如在\[26\]中一样，这个参数可能会

![](media/image7.jpeg){width="2.263888888888889in"
height="1.8333333333333333in"}

图6。5M SIFT 学习数据集的查询时间与 Mmax0 pa 参数的关系图。用箭头显示
mmax0的自动选择值2∙ m。

![](media/image8.jpeg){width="2.3333333333333335in"
height="1.9027777777777777in"}

图7。邻居选择方法的影响(基线对应于海藻酸钠)。3，启发式的海藻。4)聚类(100个随机孤立簇)和非聚类
d = 10个随机向量数据。

![](media/image9.jpeg){width="2.1527777777777777in"
height="1.8333333333333333in"}

![](media/image10.jpeg){width="1.3611111111111112in"
height="1.6111111111111112in"}

图8。在5m SIFT 学习数据集上，对于 Hierar-chical NSW，回忆错误与不同参数
m 的查询时间的关系图。

随机

![](media/image11.jpeg){width="4.833333333333333in"
height="2.0694444444444446in"}

数据集大小

对于 d = 4个随机矢量数据，对于两个 cpu. 10 m SIFT
数据集上的线程的数据集大小数目，在10m SIFT 数据集上的 NSW
得到固定的精度。

通过使用样本数据自动配置。

构造过程可以轻松有效地并行化，只需要很少的同步点(如图9所示)
，并且对索引质量没有可测量的影响。施工速度/指标质量权衡是通过
efConstruction 参数来控制的。图10给出了10m SIFT
数据集的搜索时间和索引构造时间之间的权衡，并表明在4x2.4 GHz 10核 Xeon
E5-4650 v2 CPU 服务器上，只需3分钟就可以构造出合理的 efConstruction =
100的质量索引。efConstruction
的进一步增加几乎不会带来额外的性能，但是换来的是显著更长的构建时间。

4.2复杂性分析

4.2.1搜寻复杂性

在建立精确的 De-launay
图而不是近似图的假设下，可以严格分析单个搜索的复杂度标度。假设我们已经在某一层上找到了最接近的元素(通过
Delaunay 图可以保证这一点)
，然后下降到下一层。我们可以证明在我们找到层中最接近的元素之前的平均步数是由一个常数限定的。

实际上，层与数据元素的空间位置并不相关，因此，当我们遍历图时，下一个节点属于上层的概率是固定的
p = exp (-
mL)。然而，在层上的搜索总是在到达属于较高层的元素之前终止(否则，在较高层上的搜索将在不同的元素上停止)
，因此，在第 s 步上没有到达目标的概率受 exp (s ·
mL)的限制。因此，层中的预期步数是由一个等比数列 s = 1/(1-exp (-
mL))的和限定的，这个等比数列与数据集的大小无关。

如果我们假设 Delaunay 图中一个节点的平均度在大数据集的极限内被一个常数 c
限制(对于随机 Euclid da
\[48\]来说就是这种情况，但是在奇异空间中原则上可以被破坏)
，那么一个层中距离计算的总平均数是由一个常数 c · s
限制的，与数据集的大小无关。

由于构造尺度的最大层索引的期望值为 o (log (n)) ，因此整体复杂度尺度为 o
(log (n)) ，与低维数据集的模拟结果一致。

在新南威尔士分层网络中，由于使用了每个元素有固定邻居数的近似边选择启发式算法，使得得到精确
Delaunay
图的初始假设受到了破坏。因此，为了避免陷入局部最小值，贪婪搜索算法在零层采用了回溯过程。模拟表明，至少对于低维数据(图11，d
= 4) ，所需的 ef
参数(通过回溯过程中的最小跳数来决定复杂度)的依赖性随着数据集大小的增加而饱和。回溯复杂度是相对于最终复杂度的一个加性项，因此，从经验数据来看，Delaunay
图近似的不准确性不会改变标度。

这种对 Delaunay 图近似弹性的实证研究要求具有独立于 da-taset 的 Delaunay
图边的平均数，以证明在层次新南威尔士州用常数连接近似边的效果如何。然而，Delaunay
图的平均度与维数呈指数关系\[39\]) ，因此对于高维数据(例如 d = 128)
，上述条件要求具有极大的数据集，使得这种实证研究不可行。需要进一步的分析证据来证实
Delaunay 图近似的弹性是否普遍适用于更高的维度空间。

4.2.2建筑复杂性

构造是通过所有元素的迭代插入来完成的，而元素的插入仅仅是在不同层次上的
k-ann 搜索序列，然后使用启发式算法(在固定的 efConstruction
中复杂度是固定的)。一个元素被加入的平均层数是一个常数，取决于 mL:

E l1Eln (如果 e \[1 + 1 = e \[-In (unif (0,1)) · m \] + 1 = m + 1(0,1))
mL1mL1(1)

因此，插入复杂缩放与搜索相同，这意味着至少对于相对较低维数据集，构造时间缩放为
o (n ∙ log (n))。

4.2.3内存成本

层次化 NSW
的内存消耗主要由图连接的存储来定义。每个元素的连接数对于零层是
Mmax0，对于所有其他层是 Mmax。因此，每个链接的平均内存消耗量(Mmax0 + mL
∙ Mmax)∙字节
\_。如果我们将元素的最大总数限制在大约40亿，我们可以使用4字节的无符号整数来存储连接。测试表明，典型的接近最佳
m 值的范围通常在6到48之间。这意味着 in-index
的典型内存需求(不包括数据的大小)是每个对象大约60-450字节，这与模拟结果非常一致。

5性能评估

层次 NSW 算法是在非度量空间库(nmslib)\[49\]1之上用 c + +
实现的，该库已经有了一个功能性 NSW 实现(名称为"
sw-graph")。由于库的一些限制，为了获得更好的性能，层次 NSW
实现使用自定义距离函数和 c
风格的内存管理，避免了不必要的隐式地址，并允许有效的硬件和软件预取遍历图。

比较 K-ANNS
算法的性能是一个非常重要的任务，因为随着新算法和实现的出现，最先进的技术不断变化。在这项工作中，我们集中精力与欧几里得空间中具有开源实现的最佳算法进行比较。本文提出的
Hier-archical NSW 算法的一个实现也作为开源 nmslib
库1的一部分与一个支持增量索引构造2的外部 c + +
内存高效的头文件版本一起发布。

比较部分包括四个部分: 与基线 NSW
(5.1)的比较，与欧几里得空间中的最新算法的比较(5.2)
，在一般度量空间中重新运行测试子集\[34\] ，NSW 在其中失败(5.3)
，以及与200米 SIFT 大型数据集上的最新 pq 算法的比较(5.4)。

5.1与基线 NSW 比较

对于基线 NSW 算法实现，我们使用了来自 nmslib 1.1的"
sw-graph"(与\[33,34\]中测试的实现相比略有更新)来演示速度和算法复杂性的提高(通过距离计算的数量来衡量)。

图12(a)给出了在 Core i52400 CPU (10-NN 搜索)上生成的 d =
4个随机超立方体数据的层次 NSW 与基本 NSW 算法的比较。Hierar-chical NSW
在数据集搜索期间使用更少的距离计算，特别是在高召回时。

图12(b)给出了在 d = 8的随机超立方体数据集上10-nn
搜索算法的缩放，其固定召回率为0.95。它清楚地表明，hi 分层 NSW
对于这种设置具有复杂性缩放，不比对数差，并且在任何数据集大小下都优于
NSW。由于改进的算法实现，绝对时间的性能优势(图12(c))甚至更高。

5.2欧几里得空间中的比较

主要部分的比较是在矢量数据集上进行的，使用流行的 K-ANNS 基准
ann-benchmark 3作为测试平台。测试系统利用算法的 python
绑定------它必然地运行 K-ANN 搜索1000个查询(从初始数据集中随机抽取)
，并预设算法参数，产生包含一次搜索的召回和平均时间的输出。被考虑的算法是:

1\. 来自 nmslib 1.1(" sw-graph")的基线 NSW 算法。

2.FLANN 1.8.4\[6\].一个流行的图书馆4包含几个算法，内置在
opencv5中。我们使用可用的自动调优过程和几次重新运行来推断最佳参数。

3\. Annoy6,02.02.2016 build. a popular algorithm 3.
Annoy6,02.02.2016构建流行算法

![](media/image12.jpeg){width="6.666666666666667in"
height="1.8888888888888888in"}

图12。新南威尔士州和层次新南威尔士州之间的比较:
(a)1000万个四维随机向量数据集的距离计算次数与准确性权衡;
(b-c)8维随机向量数据集的距离计算次数和原始查询时间的性能缩放。

4 https://github.com/mariusmuja/flann 1
https://github.com/searchivarius/nmslib5
https://github.com/opencv/opencv 2 https://github.com/nmslib/hnsw6
https://github.com/spotify/annoy

表1

向量空间基准上使用数据集的参数。

基于随机投影树林。

4\. vp 树。一种具有度量剪枝的通用度量空间算法\[50\] ，作为 nmslib
1.1的一部分实现。

5\. FALCONN7，版本1.2. 一种新的高效的余弦距离算法\[51\]。

比较是在具有128gb RAM 的4x Xeon E5-4650 v2Debian OS
系统上进行的。对于每一种算法，我们在每一个召回范围内仔细地选择最好的结果来评估最好的可能性能(使用测试台默认值的初始值)。所有的测试都是在单线程模式下完成的。使用具有
-ofast 优化标志的 GCC 5.3编译分层 NSW。

表1列出了所用数据集的参数和描述。对于除了手套之外的所有数据集，我们使用
l2距离。对于 GloVe，我们使用了向量归一化后的余弦距离相似度，相当于
L2。蛮力(BF)时间由 nmslib 库测量。

矢量数据的结果如图13所示。对于 SIFT，GloVE，DEEP 和 CoPhIR 数据集，层次
NSW 明显优于竞争对手很大一部分。对于低维数据(d = 4) ，层次 NSW 是

表2。

用于重复非度量数据测试子集的数据集。

与 Annoy 相比，在高召回速度方面略快一些，但是在性能方面强于其他算法。

5.3一般空间的比较

最近在一般空间(即非对称或违反三角形不等式)的算法\[34\]的比较表明，基线
NSW 算法在低维数据集上存在严重的问题。为了测试分层 NSW
算法的性能，我们从\[34\]中重复了一个测试子集，在这个子集上 NSW
表现不佳或次优。为此，我们使用了一个内置的 nmslib
测试系统，该系统具有从\[34\]运行测试的脚本。评价的算法包括 vp
树、置换技术(NAPP 和 bruteforce 滤波)\[49,55-57\]、基本的 NSW 算法和
ndescent 生成的邻近图\[29\](均与 NSW
图搜索算法配对)。正如在原始测试中一样，对于每个数据集，测试包括 NSW 或
NNDescent 的结果，取决于哪种结构表现更好。没有定制的距离函数或特殊

![](media/image13.jpeg){width="6.847222222222222in"
height="3.9166666666666665in"}

图13。层次 NSW 与 K-ANNS 算法的开源实现在5个数据集上进行10-nn
搜索的比较结果。暴力搜索法的时间被表示为 BF。

![](media/image14.jpeg){width="6.819444444444445in" height="3.875in"}

图14。层次 NSW 与来自 Non Metric Space Library 的通用空间 K-ANNS
算法在5个数据集上进行10-nn 搜索的比较结果。暴力搜索法的时间被表示为 BF。

表3。

在1b SIFT 数据集的200m 子集上比较层次 NSW 和 Faiss 的参数。

在这种情况下，对 Hierar-chical NSW 使用了内存管理，导致了一些性能损失。

这些数据集总结在表2中。数据集，空间和算法参数选择的进一步细节可以在原始工作中找到\[34\]。蛮力(BF)时间由
nmslib 库测量。

结果如图14所示。层次化 NSW 显着提高了 NSW
的性能，并且是任何测试数据集的领导者。对于维数最低的 wiki-8和
JS-divergence，在新南威尔士观测到的增强最强，几乎达到3个数量级。这是一个重要的结果，证明了层次
NSW 的稳健性，因为对于原来的 NSW，这个数据集是一个绊脚石。注意，对于
wiki-8来说，为了消除实现的影响，结果是针对距离计算数量而不是 CPU
时间展示的。

5.4与基于产品量化算法的比较。

产品量化 K-ANNS
算法\[10-17\]被认为是十亿规模数据集的最新技术，因为它们可以有效地压缩存储的数据，允许适度的
RAM 使用，同时在现代 cpu 上实现毫秒级的搜索时间。

比较层次化 NSW 的性能

![](media/image15.jpeg){width="3.013888888888889in"
height="2.5416666666666665in"}

图15来自\[13\]的200m SIFT 数据集与 Faiss 库的比较结果。插图显示了层次
NSW 的查询时间与数据集大小的比例。

针对 PQ 算法，我们使用 facebook Faiss library 8作为基线(一个具有最先进
PQ 算法\[12,15\]实现的新库，在当前手稿提交之后发布) ，用 OpenBLAS
后端编译。在具有128gb RAM 的4x Xeon E5-4650 v2服务器上对1b SIFT
数据集的200m 子集\[13\]进行测试。Ann
基准测试平台由于依赖于32位浮点格式(仅存储数据就需要超过100gb)
，因此对于这些实验来说是不可行的。为了得到 Faiss PQ
算法的结果，我们使用了具有 Faiss wiki9参数的内置脚本。对于分层 NSW
算法，我们在 nmslib
之外使用了一个特殊的构建，内存占用很小，简单的非矢量化8 https://github.
com/facebookresearch/faiss 2017 May build。从2018年开始，faiss
库有自己的层次 NSW 实现。

9 https://github. com/facebookresearch/faiss/wiki/index-1g-vectors

整数距离函数和对增量索引结构的支持。

结果如图15所示，参数总结如表3所示。在两种算法的索引构建之后，通过使用
linux" time-v"工具在单独的测试运行中测量峰值内存消耗。尽管层次化的 NSW
需要更多的
RAM，但是它可以实现更高的准确性，同时在搜索速度和索引构建方面提供了巨大的进步。

图15中的插图显示了层次 NSW
的查询时间与数据集大小的比例。请注意，缩放偏离纯对数，可能是由于数据集的维数相对较高。

6讨论

该方法利用可导航小世界图的结构分解和智能邻居选择启发式算法，克服了基本
NSW 结构的几个重要问题，提高了 K-ANN
搜索的技术水平。分层新南威尔士州提供了一个优秀的性能，是一个明确的领导者在大量的数据集，超过了开源竞争对手的大幅度的情况下，高维数据。即使对于先前的算法(NSW)已经丢失了数量级的数据集，Hierarchical
NSW 也能够排在第一位。层次化 NSW
支持连续增量索引，也可以作为一种有效的方法，获得近似的 k-NN
和相对邻域图，这是索引构造的副产品。

该方法的鲁棒性是一个很强的特点，对于实际应用具有很大的吸引力。该算法适用于广义度量空间，在本文所测试的任何数据集上都能达到最优，从而消除了对特定问题进行最优算法选择的复杂性。我们强调算法鲁棒性的重要性，因为数据可能具有复杂的结构，在整个尺度上具有不同的有效维度。例如，数据集可以由曲线上随机填充高维立方体的点组成，因此在大尺度上是高维的，在小尺度上是低维的。为了在这样的数据集中执行有效的搜索，近似最近邻算法必须在高维和低维的情况下都能很好地工作。

有几种方法可以进一步提高层次 NSW
方法的效率和适用性。还有一个有意义的参数对索引的构造有很大的影响------每层增加的连接数。潜在地，这个参数可以通过使用不同的启发式方法直接推断。比较完整的1b
SIFT 和1b DEEP 数据集\[10-14\]上的 hi 分层
NSW，并添加对元素更新和删除的支持，也是很有意思的。

与基本的 NSW
相比，该方法的一个明显缺点是失去了分布式搜索的可能性。层次化 NSW
结构中的搜索总是从顶层开始，因此由于对更高层元素的认知，不能使用\[26\]中描述的相同技术来实现结构的分布。可以使用简单的解决方案来分配结构，例如在\[6\]中研究的集群节点之间对数据进行分区，但是在这种情况下，系统的总并行吞吐量并不能很好地与计算机节点的数量相提并论。

尽管如此，还有其他可能的已知方法使这个特殊的结构分布。分层 NSW
在思想上非常类似于众所周知的一维精确搜索概率跳过列表结构，因此可以使用相同的技术使结构分布\[45\]。由于对数可伸缩性和节点上理想的均匀负载，这可能会导致与基础
NSW 相比更好的分布式性能。

7鸣谢

我们感谢 Leonid Boytsov
的许多有益的讨论，协助非公制空间图书馆的整合和对手稿的评论。我们感谢
Seth Hoffert 和 Azat Davletshin 对手稿和算法的建议，以及对 github
库中的算法作出贡献的研究人员。我们还感谢 Valery Kalyagin
对这项工作的支持。

根据第16-31-60104 mol \_ dk 号研究项目，本研究由 RFBR 资助。

8参考文献

\[1\]
D.G.Lowe，"来自尺度不变关键点的独特图像特征"，《国际计算机视觉杂志》
，第60卷，第2期，第91-110页，2004。

\[2\] s. Deerwester，s. t. Dumais，T.k. Landauer，G.w. Furnas，and R.a.
Harshman，"潜在语义学索引"，J.Amer。社会责任。通知。《科学》
，第41卷，391-407页，1990年。

\[3\] p. n. Yianilos，"一般度量空间中最近邻搜索的数据结构和算法"，载于
SODA，1993年，第93卷，第194期，第311-321页。

\[4\] g. Navarro，"通过空间近似在度量空间中搜索"，VLDB
期刊，第11卷，第1期，第28-46页，2002。

\[5\] e. s. Tellez，g. Ruiz，and e. Chavez，"最近邻搜索的 Singleton
索引"，Information Systems，2016。

\[6\] m. Muja 和 d. g.
Lowe，"高维数据的可伸缩最近邻算法"，《模式分析与机器智能》 ，IEEE
Transactions，第36卷，第11期，第2227-2240页，2014年。

\[7\] m. e. Houle 和 m. Nett，"基于排名的最近邻搜索:
减少维度依赖"，《模式分析和机器智能》 ，IEEE
交易，第37卷，第1期，第136-150页，2015年。

\[8\] a. Andoni，p. Indyk，t. Laarhoven，i. Razenshteyn，和 l.
Schmidt，《神经信息处理系统进展》
，2015，第1225-1233页，"角距离的实用和最佳 LSH"。

\[9\] p. Indyk 和 r. Motwani，"近似最近的邻居: 朝向消除维数灾难"，发表于
ACM 第30届年度计算理论研讨会会刊，1998年，第604-613页: ACM。

\[10\] J.Wang，J.Wang，g. Zeng，R.Gan，S.Li，and
B.Guo，"使用笛卡尔级联进行快速邻域图搜索"，载于《多媒体数据挖掘与分析:
斯普林格》 ，2015年，第397-417页。

\[11\] m. Norouzi，a. Punjani，and d. j.
Fleet，"多索引散列在汉明空间的快速精确搜索"，《模式分析与机器智能》
，IEEE Transactions，第36卷，第6期，第1107-1119页，2014年。

\[12\] a. Babenko 和 v. Lempitsky，《计算机视觉与模式识别》 ，2012年
IEEE 大会，第3069-3076页。

\[13\] h. Jegou，m. Douze，c.
Schmid，"产品量化最近邻搜索"，模式分析与机器智能，IEEE Transactions on
volume 33，no. 1，pp. 117-128,2011。

\[14\] a. Babenko 和 v. Lempitsky，《 IEEE
计算机视觉和模式识别会议记录》
，2016年，第2055-2063页，"十亿级深度描述符数据集的有效索引"。

\[15\] m. Douze，h. Jégou 和 f.
Perronnin，"多义代码"，欧洲计算机视觉会议，2016，第785-801页: Springer。

\[16\] y. Kalantidis 和 y.
Avrithis，"为近似最近邻搜索而进行的局部优化产品量化"，发表在 IEEE
计算机视觉和模式识别会议的进程中，2014年，第2321-2328页。

\[17\] p. Wieschollek，o. Wang，a. Sorkine-Hornung，and h. Lensch，" gpu
上的高效大规模近似最近邻搜索"，发表于2016年 IEEE
计算机视觉和模式识别会议记录，第2027-2035页。

\[18\] s. Arya and d. m. Mount，"固定维度中的近似最近邻查询"，载于
SODA，1993年，第93卷，第271-280页。

\[19\] J.Wang 和
S.Li，"大规模索引的查询驱动迭代邻域图搜索"，刊于2012年第20届 ACM
国际多媒体会议论文集，第179-188页: ACM。

\[20\]江泽民，谢丽萍，邓克强，徐文伟，王建民，《汉明空间中的快速最近邻搜索》
，载《多媒体建模》 ，2016年，第325-336页: 斯普林格。

\[21\] e. Chávez 和 e. s. Tellez，"导航 k
最近邻图解决最近邻搜索"，在模式识别的进展: Springer，2010，第270-280页。

\[22\] k. Aoyama，k. Saito，h. Sawada，and n.
Ueda，"基于降阶最近邻搜索的快速近似相似搜索"，发表于2011年第17届 ACM
SIGKDD 国际知识发现和数据挖掘会议论文集，第1055-1063页: ACM。

\[23\] g. Ruiz，e. Chávez，m. Graff，和 e. s.
tellez，"通过局部搜索找到最近邻搜索"，在相似性搜索和应用程序:
Springer，2015，第103-109页。

\[24\] r.
Paredes，"度量空间搜索图"，博士论文，智利大学，智利，2008。计算机科学系
TechReportTR/DCC-2008-10。可在 http://www.dcc.uchile.cl/\~
raparede/publ/08phdthesis.pdf，2008。

\[25\] y. Malkov，a. Ponomarenko，a. Logvinov 和 v.
Krylov，"高维一般度量空间中最近邻搜索问题的可伸缩分散式演算法"，"在相似性搜索和应用中:
斯普林格柏林海德保，2012，第132-147页。

\[26\] y. Malkov，a. Ponomarenko，a. Logvinov 和 v.
Krylov，"基于可导航的小世界图的 ap 近似最近邻算法"，《信息系统》
，第45卷，第61-68页，2014年。

\[27\] w. Pugh，《跳跃列表: 平衡树的概率替代》
，美国计算机学会通讯，第33卷，第6期，第668-676页，1990年。

C. Cartozo and p. De Los Rios，"小世界网络的扩展适航性:
精确的结果和新的见解"，Physical review letters，vol. 102，no. 23，p.
238703,2009。

\[29\] W.Dong，c. Moses，and k. Li，"泛型相似性度量的有效 k
最近邻图构造"，发表于2011年第20届万维网国际会议进程，第577-586页: ACM。

\[30\] a. Ponomarenko，y. Malkov，a. Logvinov 和 v. Krylov，" ap
近邻搜索小世界方法"，于2011年在美国佛罗里达州奥兰多举行的信息和通信技术与应用国际会议上发表。

\[31\] j · m · 克莱因伯格，《小世界中的航行》 ，《自然》
，第406卷，第6798页，第845-845页，2000年。

\[32\] m. Boguna，d. Krioukov，and K.c.
Claffy，"复杂网络的可导航性"，《自然物理学》
，第5卷，第1期，第74-80页，2009年。

\[33\] a. Ponomarenko n. Avrelin b. Naidan and l.
Boytsov，"近似最近邻搜索数据结构的比较分析"，刊于2014年第三届国际数据分析会议记录。

\[34\] b. 奈丹，l. Boytsov 和 e.
Nyberg，"排列搜索方法是有效的，但更快的搜索是可能的,"VLDB
Pro-cedings，第8卷，第12号，第1618-1629页，2015。

\[35\] d. Krioukov，f. Papadopoulos，m. Kitsak，a. Vahdat，and m.
Boguná，"复杂网络的双曲几何"，Physical Review e，volume 82，no. 3，p.
036106,2010。

\[36\] a. Gulyás，j. j. Bíró，a. k rösi，g. Rétvári，and d.
Krioukov，"作为导航游戏的纳什均衡的导航网络,"《自然通讯》
，第6卷，7651页，2015年。

\[37\] y. Lifshits 和 s.
Zhang，《最近邻居、近似重复和小世界设计的组合算法》
，发表于2009年第二十届 ACM-SIAM 离散算法年度研讨会，第318-326页:
工业和应用数学学会。

A. Karbasi，s. Ioannidis，and l. Massoulie，" From Small-World Networks
to Comparison-Based Search,"Information Theory，IEEE Transactions on
vol.61，no. 6，pp. 3056-3074,2015。

\[39\] o 博蒙特，上午。Kermarrec 和 é。Rivière，"点对点多维覆盖:
近似复杂结构"，《分布式系统原理: Springer，2007，第315-328页》。

\[40\] o. Beaumont，A.-M.Kermarrec，l. Marchal 和 é。Rivière，" VoroNet:
一个基于 Voronoi
特塞拉斯的可扩展对象网络"，发表于并行与分布式处理研讨会，2007年。IPDPS
2007.IEEE International，2007，pp. 1-10: IEEE
International，2007，第1-10页。

\[41\] j. Kleinberg，"小世界现象:
一种算法视角"，刊于《美国计算机学会第三十二届年度计算理论研讨会会刊》
，2000年，第163-170页。

J. Travers and s.
Milgram，"小世界问题的实验研究"，Sociometry，第425-443页，1969。

\[43\] d · j · 瓦茨和 s · h · 斯特罗加茨，《小世界网络的集体动力学》
，《自然》 ，第393卷，第6684页，第440-442页，1998年。

\[44\] y. a. 马尔科夫和 a.
Ponomarenko，"成长中的同质网络是自然可航行的小世界"，PloS
one，第0158162页，2016。

\[45\] m · t · 古德里奇，m · j · 纳尔逊和 j · z · 孙，"彩虹跳跃图:
一种容错的恒度分布式数据结构"，发表于2006年 ACM-SIAM
第十七届年度离散算法研讨会会刊，第384-393页:
印度工业试验与应用数学学会。

\[46\]杜桑，"有限平面集的相对邻域图"，《模式识别》
，第12卷，第4期，第261-268页，1980年。

\[47\] b. Harwood 和 t. Drummond，" FANNG: 快速近似最近邻图"，刊于2016年
IEEE 计算机视觉和模式识别会议论文集，第5713-5722页。

\[48\]德怀尔，"线性期望时间中的高维 Voronoi 图"，《离散与计算几何》
，第6卷，第3期，第343-367页，1991年。

\[49\] l. Boytsov 和 b.
Naidan，"工程高效和有效的非度量空间库"，最近邻搜索和应用:
Springer，2013，第280-293页。

\[50\] l. Boytsov 和 b. Naidan，《神经信息处理系统进展》
，2013年，第1574-1582页，"在度量和非度量空间中学习修剪"。

\[51\] a. Andoni 和 i.
Razenshteyn，"近似近邻的最优数据依赖散列"，发表于2015年美国俄勒冈州波特兰市第四十七届计算理论年会会议记录。

\[52\] j. Pennington，r. Socher 和 c. d. Manning，"手套:
词表示的全局向量"，自然语言处理中的经验方法汇编(EMNLP 2014)
，第12卷，第1532-1543页，2014。

\[53\] p. Bolettieri 等，" CoPhIR: 基于内容的图像检索测试集,"arXiv
preprint arXiv: 0905.4627,2009。

\[54\] y. LeCun，l. Bottou，y. Bengio 和 p.
Haffner，"基于梯度的学习应用于文档识别"，《 IEEE 会刊》
，卷86，第11期，第2278-2324页，1998年。

\[55\] e · 查韦斯，m · 格拉夫，g · 纳瓦罗和 e · 特莱兹，"用 k
个最近的引用进行近邻搜索"，《信息系统》 ，第51卷，第43-61页，2015年。

\[56\] e. c. Gonzalez，k. Figueroa，and g.
Navarro，"通过排列顺序进行有效的接近性检索"，《模式分析与机器智能》
，IEEE Transactions，第30卷，第9期，第1647-1658页，2008。

\[57\] e. s. Tellez e. Chávez 和 g.
Navarro，"简洁的最近邻搜索"，《信息系统》
，第38卷，第7期，第1019-1030页，2013年。

\[58\] p. Sojka，"利用大型语料库进行主题建模的软件框架"，《 LREC 2010年
NLP 框架面临的新挑战研讨会进展》 ，2010年: Citeseer。

\[59\] c.
beeck，"基于距离的基于内容的多媒体检索相似性模型"，莱茵-威斯特法伦理工大学图书馆，亚琛，2013。

![](media/image16.jpeg){width="0.8888888888888888in"
height="1.1527777777777777in"}

2009年，Yury a. Malkov
获得了下诺夫哥罗德州立大学的物理学硕士学位，2015年获得了 RAS
应用物理研究所的激光物理学博士学位。他是20多篇物理和计算机科学论文的作者。Yury
目前在莫斯科的三星人工智能中心担任项目负责人。他目前的研究兴趣包括深度学习、可扩展的相似性搜索、生物学和最近邻搜索

人工神经网络。

德米特里 · a ·
亚舒宁于2009年获得下诺夫哥罗德州立大学物理学硕士学位，2015年获得拉斯维加斯应用物理研究所激光物理学博士学位。从2008年到2012年，他在梅拉河网络工程(Mera
Net-works)工作。他是10多篇物理学论文的作者。Dmitry 目前在 Intelli-Vision
工作，是一名顶尖的研究工程师。他目前的研究兴趣包括最近邻搜索、计算机视觉和深度学习。
